
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Implementation &#8212; Calibration of the GEOtop model using evolutionary algorithms on supercomputers</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://stefanocampanella.github.io/MHPC-project/method/implementation.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example GEOtop Calibration Report" href="../results/DOMES.html" />
    <link rel="prev" title="Tools" href="tools.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://stefanocampanella.github.io/MHPC-project/method/implementation.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Implementation" />
<meta property="og:description" content="Implementation  Talk is cheap, show me the code.  Linus Torvalds  Model and Objective Function  As discussed in the previous chapter, in order to have a functio" />
<meta property="og:image"       content="https://stefanocampanella.github.io/MHPC-project/_static/logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Calibration of the GEOtop model using evolutionary algorithms on supercomputers</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../frontmatter/summary.html">
   Summary and Outline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../frontmatter/acknowledgements.html">
   Acknowledgements
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction and Motivations
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/calibration.html">
   GEOtop calibration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../intro/hpc.html">
   The need for HPC
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Problem, Methodology and Implementation
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="problem.html">
   Derivative-free Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tools.html">
   Tools
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Implementation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Results
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../results/DOMES.html">
   Example GEOtop Calibration Report
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../results/scaling.html">
   Scaling Analysis and Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../results/conclusions.html">
   Conclusions
  </a>
 </li>
</ul>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../backmatter/final.html">
   Final Thoughts Beyond the Scope of the Thesis
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/method/implementation.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-and-objective-function">
   Model and Objective Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-closer-look-at-the-optimization-loop">
   A Closer Look at the Optimization Loop
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="implementation">
<h1>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h1>
<blockquote class="epigraph">
<div><p>Talk is cheap, show me the code.</p>
<p class="attribution">—Linus Torvalds</p>
</div></blockquote>
<div class="section" id="model-and-objective-function">
<h2>Model and Objective Function<a class="headerlink" href="#model-and-objective-function" title="Permalink to this headline">¶</a></h2>
<p>As discussed in the previous chapter, in order to have a functioning interface to the GEOtop model using GEOtoPy it is necessary to specify how to do preprocessing of the data (basically meteorological forcings and input parameters) and postprocessing of simulation results. The following is the implementation used for simulations with uniform soil parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">importlib.resources</span> <span class="k">as</span> <span class="nn">resources</span>
<span class="kn">from</span> <span class="nn">geotopy</span> <span class="kn">import</span> <span class="n">GEOtop</span>
<span class="kn">from</span> <span class="nn">mhpc_project.utils</span> <span class="kn">import</span> <span class="n">postprocess_full</span>

<span class="k">class</span> <span class="nc">UniformSoilModel</span><span class="p">(</span><span class="n">GEOtop</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">resources</span><span class="o">.</span><span class="n">open_text</span><span class="p">(</span><span class="s1">&#39;mhpc_project&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform_defaults.json&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">default_settings</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">working_dir</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">settings</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_settings</span><span class="p">)</span>
        <span class="n">settings</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clone_into</span><span class="p">(</span><span class="n">working_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_inpts_file</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">settings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">working_dir</span><span class="p">):</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_settings</span><span class="p">(</span><span class="n">working_dir</span> <span class="o">/</span> <span class="s1">&#39;geotop.inpts&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">postprocess_full</span><span class="p">(</span><span class="n">settings</span><span class="p">,</span> <span class="n">working_dir</span><span class="p">)</span>
</pre></div>
</div>
<p>In this case, preprocessing is trivial and consist of copying the files to the proper directory and patching the <code class="docutils literal notranslate"><span class="pre">geotop.inpts</span></code> with the new value of the parameters. Notice that the <code class="docutils literal notranslate"><span class="pre">self.settings</span></code> dictionary of settings is copied to avoid nefarious side effects. Preprocessing also takes care of appling some defaults settings, which are assumed in the postprocessing phase.</p>
<p>The postprocess is just a wrapper around a utility function. This is because the same postprocessing is done also in the variable soil model, discussed below. In this way one can avoid code duplication without introducing a intermediate class in the inheritance scheme.</p>
<p>Once having a functioning model, the objective function can be easily implemented.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">observations</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">run_in</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="o">*</span><span class="n">candidate</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">candidate</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="n">CalledProcessError</span><span class="p">,</span> <span class="n">TimeoutExpired</span><span class="p">):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">compare</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">observations</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">compare</span></code> function should return the loss value. A good choice is to use the Kling-Gupta or Nash-Sutcliffe efficiencies, which are well-suited for hydrological models, notice however that higher number of these correspond to better overlap of simulation and observations.</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">TemporaryDirectory</span></code> from the tempfile module allows running the model in <code class="docutils literal notranslate"><span class="pre">tmpfs</span></code> (i.e. in RAM) and automatic deletion of files on exit (also in case of exceptions and canceled Dask task). The <code class="docutils literal notranslate"><span class="pre">CalledProcessError</span></code> and <code class="docutils literal notranslate"><span class="pre">TimeoutExpired</span></code> exceptions from the subprocess module must be caught since they represent routine GEOtop failures. Other exceptions will be propagated since they signal abnormal behaviours.</p>
</div>
<div class="section" id="a-closer-look-at-the-optimization-loop">
<h2>A Closer Look at the Optimization Loop<a class="headerlink" href="#a-closer-look-at-the-optimization-loop" title="Permalink to this headline">¶</a></h2>
<p>A wide class of algorithms can be implemented using the unique interface described in <span id="id1">[<a class="reference internal" href="tools.html#id19"><span>CHP+13</span></a>]</span>, and the ones sketched in the chapter <a class="reference internal" href="problem.html#content-optimization"><span class="std std-ref">Derivative-free Optimization</span></a> belong to them. Let’s say we want to minimize the objective function <code class="docutils literal notranslate"><span class="pre">f</span></code>, the optimization loop will look like the following</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="ow">not</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">stop</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The pseudocode is rather self explicative: the <code class="docutils literal notranslate"><span class="pre">optimizer.stop</span></code> method must implement some stopping criterion, the <code class="docutils literal notranslate"><span class="pre">optimizer.ask</span></code> method suggests a new point where to evaluate the objective function, and <code class="docutils literal notranslate"><span class="pre">optimizer.tell</span></code> communicates the result to the optimizer. This design allows decoupling the optimizer from the objective function.</p>
<p>Since the state of the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> object contains the information about the history of evaluations, different criteria are possible, such as asking a decrease of the objective above some threshold. The simplest is to use an internal counter to allow a maximum number of objective evaluations, the budget in the Nevergrad parlance. It is crucial to notice that the number of <code class="docutils literal notranslate"><span class="pre">optimizer.ask</span></code> calls can differ from the one of <code class="docutils literal notranslate"><span class="pre">optimizer.tell</span></code> calls.</p>
<p>As it is, the loop is fully serial. We need an optimization algorithm capable of suggesting several points at ones to make it parallel. The requirement is non-trivial, for example Bayesian optimization does not fulfill it. Evolutionary algorithms generally satisfy the requirement, since individuals of the same generation are independent one another.</p>
<p>A parallelizable loop using generation count as stopping criterion will look like the following.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_generations</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<p>In theory, <code class="docutils literal notranslate"><span class="pre">optimizer.ask</span></code> could be read-only, and the first loop could be executed in parallel. In practice, it must change the state of the internal pseudo-random generator. Since <code class="docutils literal notranslate"><span class="pre">optimizer.tell</span></code> changes the state of the object (with exception of random search), concurrent execution of the third loop is guaranteed to cause race conditions unless <code class="docutils literal notranslate"><span class="pre">optimizer.tell</span></code> uses some mutex. However, both <code class="docutils literal notranslate"><span class="pre">optimizer.ask</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer.tell</span></code> are not supposed to be expensive to call<a class="footnote-reference brackets" href="#expensive-ask" id="id2">1</a>, hence their loops can be executed in serial fashion without performance degradation.</p>
<p>When the objective function evaluation is time-consuming, as it is the case for GEOtop, most of the time is spent in the second loop. The objective loop is embarrassingly parallel and can be executed concurrently for example using futures. Let’s suppose to have a Dask Client <code class="docutils literal notranslate"><span class="pre">client</span></code>, the loop becomes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_generations</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">futures</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">futures</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<p>The first two loops can be fused, as well as the second two. Notice that Dask assumes that <code class="docutils literal notranslate"><span class="pre">f</span></code> is a pure function (otherwise, the whole computation would not make sense anyway).</p>
<p>The previous design however has a serious flaw: the third loop is executed synchronously (there is no event loop) and <code class="docutils literal notranslate"><span class="pre">future.result()</span></code> is blocking. Therefore, the interpreter will wait the first future, then the second, and so go on. However, since the execution time of <code class="docutils literal notranslate"><span class="pre">f</span></code> is random (and varies in a large interval of values), some results may be ready much before their turn. Fortunately Dask Distributed as the <code class="docutils literal notranslate"><span class="pre">as_completed</span></code> class, which iterates the futures as soon as they are done.</p>
<p>However, since we lost the information about the order of the results, we need to use a small wrapper that keeps track of the argument and the loss.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_generations</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">popsize</span><span class="p">):</span>
        <span class="n">futures</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
   
    <span class="n">to_tell</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">futures</span><span class="p">):</span>
        <span class="n">to_tell</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
        
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">to_tell</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>Such optimization loop still does not take into account objective function failures. In our implementation failing computations return nan. We can check that the result is valid using the <code class="docutils literal notranslate"><span class="pre">isfinite</span></code> function from Numpy. It is possible to elegantly solve the problem by submitting other computations to <code class="docutils literal notranslate"><span class="pre">as_completed</span></code>. Indeed, it has two methods <code class="docutils literal notranslate"><span class="pre">as_completed.add</span></code> and <code class="docutils literal notranslate"><span class="pre">as_completed.update</span></code> which allow adding one or more futures to the queue respectively, and a <code class="docutils literal notranslate"><span class="pre">as_completed.count()</span></code> method which counts how many futures are still in the queue.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">completed_queue</span> <span class="o">=</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>   
<span class="n">to_tell</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">completed_queue</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">to_tell</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_tell</span><span class="p">)</span> <span class="o">+</span> <span class="n">completed_queue</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">popsize</span><span class="p">:</span>
        <span class="n">new_x</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        <span class="n">new_future</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">new_x</span><span class="p">)</span>
        <span class="n">completed_queue</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_future</span><span class="p">)</span>
</pre></div>
</div>
<p>The previous code works since to exit the loop <code class="docutils literal notranslate"><span class="pre">completed_queue</span></code> must be empty. If <code class="docutils literal notranslate"><span class="pre">completed_queue</span></code> is empty, then bottom of the loop has been reached without a insertion of a new future, that is <code class="docutils literal notranslate"><span class="pre">len(to_tell)</span> <span class="pre">+</span> <span class="pre">completed_queue.count()</span> <span class="pre">&lt;</span> <span class="pre">popsize</span></code> must have been false. But <code class="docutils literal notranslate"><span class="pre">completed_queue.count()</span></code> is equal to zero, hence <code class="docutils literal notranslate"><span class="pre">len(to_tell)</span> <span class="pre">&gt;=</span> <span class="pre">popsize</span></code>. However, the number of failures equals the number of insertions, hence <code class="docutils literal notranslate"><span class="pre">len(to_tell)</span> <span class="pre">==</span> <span class="pre">popsize</span></code>.</p>
<p>Let’s consider what happen when we reach the end of a generation. There are <code class="docutils literal notranslate"><span class="pre">popsize</span> <span class="pre">-</span> <span class="pre">1</span></code> elements in <code class="docutils literal notranslate"><span class="pre">to_tell</span></code>, and if the objective fails a single new future is added to <code class="docutils literal notranslate"><span class="pre">completed_queue</span></code>: all CPUs except one will wait in idle. A better idea is to speculatively execute more objective functions, so to increase the chances that at least one of them does not fail.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">completed_queue</span> <span class="o">=</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>   
<span class="n">to_tell</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">completed_queue</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">to_tell</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_tell</span><span class="p">)</span> <span class="o">+</span> <span class="n">completed_queue</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">popsize</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_new_futures</span><span class="p">):</span>
            <span class="n">new_x</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
            <span class="n">new_future</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">new_x</span><span class="p">)</span>
            <span class="n">completed_queue</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_future</span><span class="p">)</span>
</pre></div>
</div>
<p>In this way, there will be a buffer of approximately <code class="docutils literal notranslate"><span class="pre">num_new_futures</span></code> extra futures. Indeed, the upper bound for the size of the queue is <code class="docutils literal notranslate"><span class="pre">popsize</span> <span class="pre">-</span> <span class="pre">len(to_tell)</span> <span class="pre">+</span> <span class="pre">num_new_futures</span> <span class="pre">-</span> <span class="pre">1</span></code>. However, with this modification there is no guarantee that at the end of a calculation we have <code class="docutils literal notranslate"><span class="pre">popsize</span></code> elements in <code class="docutils literal notranslate"><span class="pre">to_tell</span></code>. Usually this is not a problem, since the optimizer will throw away the worst individuals (or include them in computations, in a non-elitist fashion). However, we can enforce the old behaviour using a <code class="docutils literal notranslate"><span class="pre">break</span></code> statement and <code class="docutils literal notranslate"><span class="pre">completed_queue.clear()</span></code>. When the latter is called, the futures still in the queue are garbage collected, and Dask cancels the corresponding computations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">completed_queue</span> <span class="o">=</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>   
<span class="n">to_tell</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">completed_queue</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">to_tell</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_tell</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">popsize</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_tell</span><span class="p">)</span> <span class="o">+</span> <span class="n">completed_queue</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">popsize</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_new_futures</span><span class="p">):</span>
                <span class="n">new_x</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
                <span class="n">new_future</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">new_x</span><span class="p">)</span>
                <span class="n">completed_queue</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">new_future</span><span class="p">)</span>
<span class="n">completed_queue</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<p>However, this introduces a bias: futures that terminates earlier have more chance to be reported to the optimizer, whatever their loss is. This new behaviour is located near the end of a generation, when the computation start to consume the buffer, and it is more evident the larger <code class="docutils literal notranslate"><span class="pre">num_new_futures</span></code>.</p>
<p>Let’s suppose that we are able to guess how many computations will be successful. In this case, we could add to the queue only the futures that will be consumed. If the fraction of valid futures in the queue is <code class="docutils literal notranslate"><span class="pre">r</span></code> then we will need to add new futures to the queue only if <code class="docutils literal notranslate"><span class="pre">len(to_tell)</span> <span class="pre">+</span> <span class="pre">r</span> <span class="pre">*</span> <span class="pre">completed_queue.count()</span> <span class="pre">&lt;</span> <span class="pre">popsize</span></code>. Not only, we can now get rid of the free parameter <code class="docutils literal notranslate"><span class="pre">num_new_futures</span></code>. Indeed, if <code class="docutils literal notranslate"><span class="pre">r</span></code> can be expected to stay constant within a generation, a reasonable heuristic is to add each time <code class="docutils literal notranslate"><span class="pre">(popsize</span> <span class="pre">-</span> <span class="pre">len(to_tell)</span> <span class="pre">-</span> <span class="pre">r</span> <span class="pre">*</span> <span class="pre">completed_queue.count())</span> <span class="pre">/</span> <span class="pre">r</span></code> new futures.</p>
<p>The actual optimization loop used implements this strategy, estimating <code class="docutils literal notranslate"><span class="pre">r</span></code> as the weighted average success rate using the following function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># log is a list of triples [(individual, loss, execution time)]</span>
<span class="k">def</span> <span class="nf">average_success_rate</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">successes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">log</span><span class="p">)]</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">log</span><span class="p">))]</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">x</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">successes</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1.0</span>
</pre></div>
</div>
<p>In this way, the success rate looses memory of older evaluations. The timescale parameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is chosen as <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">popsize</span></code>.</p>
<p>However, it turns out that this strategy fails when the number of missing futures is small. For this reason the actual optimization loop implements also an <code class="docutils literal notranslate"><span class="pre">overshoot</span></code> parameter that allows to submit more new futures than estimated (but introducing again a bias related to execution times). Also, the actual implementation prefetches futures in batches, and pre-scatters the data across the Dask cluster.</p>
<p id="id3"><dl class="citation">
<dt class="label" id="id14"><span class="brackets"><a class="fn-backref" href="#id1">CHP+13</a></span></dt>
<dd><p>Y. Collette, N. Hansen, G. Pujol, D. Salazar Aponte, and R. Le Riche. Object-oriented programming of optimizers–examples in scilab. <em>Multidisciplinary Design Optimization in Computational Mechanics</em>, pages 499–538, 2013.</p>
</dd>
</dl>
</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="expensive-ask"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>This is true within a generation. From one generation and the next, in case of large population size, the optimizer can perform expensive computations.</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./method"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="tools.html" title="previous page">Tools</a>
    <a class='right-next' id="next-link" href="../results/DOMES.html" title="next page">Example GEOtop Calibration Report</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Stefano Campanella<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>