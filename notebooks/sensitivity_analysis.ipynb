{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example of Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Defaults\n",
    "n_samples = 1024 * 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dask.bag as db\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster as Cluster\n",
    "\n",
    "from SALib.sample import latin\n",
    "from SALib.analyze import delta as delta_mim\n",
    "\n",
    "from mhpc_project.matsch_b2 import Variables, CalibrationModel, Loss\n",
    "from geotopy.measures import KGE\n",
    "from geotopy.utils import date_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "observations = pd.read_csv('../data/Matsch B2/obs.csv',\n",
    "                           na_values=['-9999', '-99.99'],\n",
    "                           usecols=[0, 7],\n",
    "                           parse_dates=[0],\n",
    "                           date_parser=date_parser,\n",
    "                           index_col=0,\n",
    "                           squeeze=True)\n",
    "observations.index.rename('datetime', inplace=True)\n",
    "model = CalibrationModel('../data/Matsch B2/geotop', run_args={'timeout': 120})\n",
    "variables = Variables('../data/Matsch B2/variables.csv')\n",
    "measure = KGE(observations)\n",
    "loss = Loss(model, variables, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem = {'num_vars': variables.num_vars,\n",
    "           'names': variables.names,\n",
    "           'bounds': list(repeat((0.0, 1.0), variables.num_vars))}\n",
    "\n",
    "samples = latin.sample(problem, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while remaining_budget or self._running_jobs or self._finished_jobs:\n",
    "            # # # # # Update optimizer with finished jobs # # # # #\n",
    "            # this is the first thing to do when resuming an existing optimization run\n",
    "            # process finished\n",
    "            if self._finished_jobs:\n",
    "                if (remaining_budget or sleeper._start is not None) and not first_iteration:\n",
    "                    # ignore stop if no more suggestion is sent\n",
    "                    # this is an ugly hack to avoid warnings at the end of steady mode\n",
    "                    sleeper.stop_timer()\n",
    "                while self._finished_jobs:\n",
    "                    x, job = self._finished_jobs[0]\n",
    "                    result = job.result()\n",
    "                    if multiobjective:  # hack\n",
    "                        result = objective_function.compute_aggregate_loss(job.result(), *x.args, **x.kwargs)  # type: ignore\n",
    "                    self.tell(x, result)\n",
    "                    self._finished_jobs.popleft()  # remove it after the tell to make sure it was indeed \"told\" (in case of interruption)\n",
    "                    if verbosity:\n",
    "                        print(f\"Updating fitness with value {job.result()}\")\n",
    "                if verbosity:\n",
    "                    print(f\"{remaining_budget} remaining budget and {len(self._running_jobs)} running jobs\")\n",
    "                    if verbosity > 1:\n",
    "                        print(\"Current pessimistic best is: {}\".format(self.current_bests[\"pessimistic\"]))\n",
    "            elif not first_iteration:\n",
    "                sleeper.sleep()\n",
    "            # # # # # Start new jobs # # # # #\n",
    "            if not batch_mode or not self._running_jobs:\n",
    "                new_sugg = max(0, min(remaining_budget, self.num_workers - len(self._running_jobs)))\n",
    "                if verbosity and new_sugg:\n",
    "                    print(f\"Launching {new_sugg} jobs with new suggestions\")\n",
    "                for _ in range(new_sugg):\n",
    "                    args = self.ask()\n",
    "                    self._running_jobs.append((args, executor.submit(func, *args.args, **args.kwargs)))\n",
    "                if new_sugg:\n",
    "                    sleeper.start_timer()\n",
    "            remaining_budget = self.budget - self.num_ask\n",
    "            # split (repopulate finished and runnings in only one loop to avoid\n",
    "            # weird effects if job finishes in between two list comprehensions)\n",
    "            tmp_runnings, tmp_finished = [], deque()\n",
    "            for x_job in self._running_jobs:\n",
    "                (tmp_finished if x_job[1].done() else tmp_runnings).append(x_job)\n",
    "            self._running_jobs, self._finished_jobs = tmp_runnings, tmp_finished\n",
    "            first_iteration = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bag = db.from_sequence(samples, npartitions=512).map(loss)\n",
    "losses = bag.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "indices = np.isfinite(losses)\n",
    "good_samples = samples[indices]\n",
    "good_losses = losses[indices]\n",
    "\n",
    "SA = delta_mim.analyze(problem, good_samples, good_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SA.to_df().sort_values('delta', key=np.abs, ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
